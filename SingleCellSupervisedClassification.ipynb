{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import confusion_matrix, adjusted_rand_score\n",
    "\n",
    "import scanpy as sc\n",
    "sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3)\n",
    "sc.settings.set_figure_params(dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining class that contains functions that will perform the mapping with XGBoost and plot the results\n",
    "class TimeMapping():\n",
    "    \n",
    "    # xgbclassifier will run the feature selection, training and validation, and testing\n",
    "    def xgbclassifier(\n",
    "        self,\n",
    "        train_anndata,\n",
    "        test_anndata,\n",
    "        max_cells_per_ident = 700,\n",
    "        train_frac = 0.7\n",
    "        ): \n",
    "        \n",
    "        \n",
    "        self.numbertrainclasses = len(train_anndata.obs.leiden.values.categories)\n",
    "        self.numbertestclasses = len(test_anndata.obs.leiden.values.categories)\n",
    "\n",
    "        #Splitting the cell barcodes into a training set and validation set based on the minimum of 70% of cells or 700 cells\n",
    "        #Creating array of the labels for each cell (the cluster each cell barcode belongs too)\n",
    "        training_set_train = []\n",
    "        training_label_train = []\n",
    "\n",
    "        for i in train_anndata.obs.leiden.values.categories.values:\n",
    "            cells_in_clust = train_anndata.obs.index[train_anndata.obs.leiden.values == i]\n",
    "            n = min(max_cells_per_ident,round(len(cells_in_clust)*train_frac))\n",
    "            train_temp = np.random.choice(cells_in_clust,n,replace = False)\n",
    "            if len(train_temp) < 100:\n",
    "                train_temp_bootstrap = np.random.choice(train_temp, size = 100 - int(len(train_temp)))\n",
    "                train_temp = np.hstack([train_temp_bootstrap, train_temp])\n",
    "            training_set_train = np.hstack([training_set_train,train_temp])\n",
    "            training_label_train = np.hstack([training_label_train,np.repeat(int(i),len(train_temp))])\n",
    "\n",
    "        training_set_test = []\n",
    "        training_label_test = []\n",
    "\n",
    "        for i in test_anndata.obs.leiden.values.categories.values:\n",
    "            cells_in_clust = test_anndata.obs.index[test_anndata.obs.leiden.values == i]\n",
    "            n = min(max_cells_per_ident,round(len(cells_in_clust)*train_frac))\n",
    "            train_temp = np.random.choice(cells_in_clust,n,replace = False)\n",
    "            if len(train_temp) < 100:\n",
    "                train_temp_bootstrap = np.random.choice(train_temp, size = 100 - int(len(train_temp)))\n",
    "                train_temp = np.hstack([train_temp_bootstrap, train_temp])\n",
    "            training_set_test = np.hstack([training_set_test,train_temp])\n",
    "            training_label_test = np.hstack([training_label_test,np.repeat(int(i),len(train_temp))])\n",
    "\n",
    "        train_index_train = []\n",
    "        for i in training_set_train:\n",
    "            train_index_train.append(np.where(train_anndata.obs.index.values == i)[0][0])\n",
    "\n",
    "        train_index_test = []\n",
    "        for i in training_set_test:\n",
    "            train_index_test.append(np.where(test_anndata.obs.index.values == i)[0][0])\n",
    "\n",
    "        train_matrix_train = xgb.DMatrix(data = train_anndata.raw.X.A[train_index_train,:], label = training_label_train, feature_names = train_anndata.var.index.values)\n",
    "\n",
    "        train_matrix_test = xgb.DMatrix(data = test_anndata.raw.X.A[train_index_test,:], label = training_label_test, feature_names = test_anndata.var.index.values)\n",
    "\n",
    "        del training_set_train, training_label_train, training_set_test, training_label_test, train_index_train, train_index_test\n",
    "\n",
    "        #Defining parameters for the XGBoost Model\n",
    "        xgb_params_train = {\n",
    "            'objective':'multi:softprob',\n",
    "            'eval_metric':'mlogloss',\n",
    "            'num_class':self.numbertrainclasses,\n",
    "            'eta':0.2,\n",
    "            'max_depth':6,\n",
    "            'subsample': 0.6}\n",
    "        nround = 200\n",
    "\n",
    "        #Fitting the XGBoost Model to the training data\n",
    "        bst_model_train = xgb.train(\n",
    "            params = xgb_params_train,\n",
    "            dtrain = train_matrix_train,\n",
    "            num_boost_round = nround)\n",
    "\n",
    "        xgb_params_test = {\n",
    "            'objective':'multi:softprob',\n",
    "            'eval_metric':'mlogloss',\n",
    "            'num_class':self.numbertestclasses,\n",
    "            'eta':0.2,\n",
    "            'max_depth':6,\n",
    "            'subsample': 0.6}\n",
    "        nround = 200\n",
    "\n",
    "        #Fitting the XGBoost Model to the testing data\n",
    "        bst_model_test = xgb.train(\n",
    "            params = xgb_params_test,\n",
    "            dtrain = train_matrix_test,\n",
    "            num_boost_round = nround)\n",
    "\n",
    "        train_xgboost_scores = bst_model_train.get_score(importance_type=\"gain\")\n",
    "        sort_train_scores = {k: v for k, v in sorted(train_xgboost_scores.items(), key=lambda item: item[1], reverse = True)[:500]}\n",
    "        top500genestrain = list(sort_train_scores.keys())\n",
    "\n",
    "        test_xgboost_scores = bst_model_test.get_score(importance_type=\"gain\")\n",
    "        sort_test_scores = {k: v for k, v in sorted(test_xgboost_scores.items(), key=lambda item: item[1], reverse = True)[:500]}\n",
    "        top500genestest = list(sort_test_scores.keys())\n",
    "\n",
    "        common_top_genes = np.array([i for i in top500genestrain if i in top500genestest]) #These are the features that we will use for training, validating and testing\n",
    "\n",
    "        del train_matrix_train, train_matrix_test, bst_model_train, bst_model_test, train_xgboost_scores, sort_train_scores, top500genestrain, test_xgboost_scores, sort_test_scores, top500genestest\n",
    "\n",
    "        #Train XGBoost on 70% of training data and validate on the remaining data\n",
    "        common_top_genes_index_train = []\n",
    "        for i in common_top_genes:\n",
    "            common_top_genes_index_train.append(np.where(train_anndata.var.index.values == i)[0][0])\n",
    "\n",
    "        training_set_train_70 = []\n",
    "        validation_set_train_70 = []\n",
    "        training_label_train_70 = []\n",
    "        validation_label_train_70 = []\n",
    "\n",
    "        for i in train_anndata.obs.leiden.values.categories.values:\n",
    "            cells_in_clust = train_anndata.obs.index[train_anndata.obs.leiden.values == i]\n",
    "            n = min(max_cells_per_ident,round(len(cells_in_clust)*train_frac))\n",
    "            train_temp = np.random.choice(cells_in_clust,n,replace = False)\n",
    "            validation_temp = np.setdiff1d(cells_in_clust, train_temp)\n",
    "            if len(train_temp) < 100:\n",
    "                train_temp_bootstrap = np.random.choice(train_temp, size = 100 - int(len(train_temp)))\n",
    "                train_temp = np.hstack([train_temp_bootstrap, train_temp])\n",
    "            training_set_train_70 = np.hstack([training_set_train_70,train_temp])\n",
    "            validation_set_train_70 = np.hstack([validation_set_train_70,validation_temp])\n",
    "            training_label_train_70 = np.hstack([training_label_train_70,np.repeat(int(i),len(train_temp))])\n",
    "            validation_label_train_70 = np.hstack([validation_label_train_70,np.repeat(int(i),len(validation_temp))])\n",
    "\n",
    "        train_index_train_70 = []\n",
    "        for i in training_set_train_70:\n",
    "            train_index_train_70.append(np.where(train_anndata.obs.index.values == i)[0][0])\n",
    "        validation_index_train_70 = []\n",
    "        for i in validation_set_train_70:\n",
    "            validation_index_train_70.append(np.where(train_anndata.obs.index.values == i)[0][0])\n",
    "\n",
    "        train_matrix_train_70 = xgb.DMatrix(data = train_anndata.raw.X.A[:,common_top_genes_index_train][train_index_train_70,:], label = training_label_train_70)\n",
    "        validation_matrix_train_70 = xgb.DMatrix(data = train_anndata.raw.X.A[:,common_top_genes_index_train][validation_index_train_70,:], label = validation_label_train_70)\n",
    "\n",
    "        del training_set_train_70, validation_set_train_70, training_label_train_70, train_index_train_70, validation_index_train_70\n",
    "\n",
    "        bst_model_train_70 = xgb.train(\n",
    "            params = xgb_params_train,\n",
    "            dtrain = train_matrix_train_70,\n",
    "            num_boost_round = nround)\n",
    "\n",
    "        validation_pred_train_70 = bst_model_train_70.predict(data = validation_matrix_train_70)\n",
    "\n",
    "        valid_predlabels_train_70 = np.zeros((validation_pred_train_70.shape[0]))\n",
    "        for i in range(validation_pred_train_70.shape[0]):\n",
    "            valid_predlabels_train_70[i] = np.argmax(validation_pred_train_70[i,:])\n",
    "        \n",
    "        del train_matrix_train_70, validation_matrix_train_70, validation_pred_train_70\n",
    "\n",
    "        #Train XGBoost on the full training data\n",
    "        training_set_train_full = []\n",
    "        training_label_train_full = []\n",
    "\n",
    "        for i in train_anndata.obs.leiden.values.categories.values:\n",
    "            train_temp = train_anndata.obs.index[train_anndata.obs.leiden.values == i]\n",
    "            if len(train_temp) < 100:\n",
    "                train_temp_bootstrap = np.random.choice(train_temp, size = 100 - int(len(train_temp)))\n",
    "                train_temp = np.hstack([train_temp_bootstrap, train_temp])\n",
    "            training_set_train_full = np.hstack([training_set_train_full,train_temp])\n",
    "            training_label_train_full = np.hstack([training_label_train_full,np.repeat(int(i),len(train_temp))])\n",
    "\n",
    "        train_index_full = []\n",
    "        for i in training_set_train_full:\n",
    "            train_index_full.append(np.where(train_anndata.obs.index.values == i)[0][0])\n",
    "\n",
    "        full_training_data = xgb.DMatrix(data = train_anndata.raw.X.A[:,common_top_genes_index_train][train_index_full,:], label = training_label_train_full)\n",
    "\n",
    "        del common_top_genes_index_train, training_set_train_full, training_label_train_full, train_index_full\n",
    "\n",
    "        bst_model_full_train = xgb.train(\n",
    "            params = xgb_params_train,\n",
    "            dtrain = full_training_data,\n",
    "            num_boost_round = nround)\n",
    "\n",
    "        #Predict the testing cluster labels\n",
    "        common_top_genes_index_test = []\n",
    "        for i in common_top_genes:\n",
    "            common_top_genes_index_test.append(np.where(test_anndata.var.index.values == i)[0][0])\n",
    "\n",
    "        full_testing_data = xgb.DMatrix(data = test_anndata.raw.X.A[:,common_top_genes_index_test])\n",
    "        test_prediction = bst_model_full_train.predict(data = full_testing_data)\n",
    "\n",
    "        del bst_model_full_train, full_testing_data\n",
    "\n",
    "        test_predlabels = np.zeros((test_prediction.shape[0]))\n",
    "        for i in range(test_prediction.shape[0]):\n",
    "            if np.max(test_prediction[i,:]) > 1.1*(1/self.numbertrainclasses):\n",
    "                test_predlabels[i] = np.argmax(test_prediction[i,:])\n",
    "            else:\n",
    "                test_predlabels[i] = self.numbertrainclasses\n",
    "\n",
    "        test_labels = np.zeros(len(test_anndata.obs.leiden.values))\n",
    "        for i,l in enumerate(test_anndata.obs.leiden.values):\n",
    "            test_labels[i] = int(l)\n",
    "\n",
    "        return validation_label_train_70, valid_predlabels_train_70, test_labels, test_predlabels\n",
    "\n",
    "    #plotConfusionMatrix will take the results from the xgboost classifier and plot them\n",
    "    def plotConfusionMatrix(\n",
    "        self,\n",
    "        ytrue,\n",
    "        ypred,\n",
    "        type,\n",
    "        save_as,\n",
    "        title = '',\n",
    "        xaxislabel = '',\n",
    "        yaxislabel = ''\n",
    "        ):\n",
    "        \n",
    "        confusionmatrix = confusion_matrix(y_true = ytrue, y_pred = ypred)\n",
    "        if type == 'mapping':\n",
    "            if self.numbertrainclasses in ypred:\n",
    "                confusionmatrix = confusionmatrix[0:self.numbertestclasses,0:self.numbertrainclasses+1]\n",
    "            else:\n",
    "                confusionmatrix = confusionmatrix[0:self.numbertestclasses,0:self.numbertrainclasses]\n",
    "        confmatpercent = np.zeros(confusionmatrix.shape)\n",
    "        for i in range(confusionmatrix.shape[0]):\n",
    "            if np.sum(confusionmatrix[i,:]) != 0:\n",
    "                confmatpercent[i,:] = confusionmatrix[i,:]/np.sum(confusionmatrix[i,:])\n",
    "            else:\n",
    "                confmatpercent[i,:] = confusionmatrix[i,:]\n",
    "        diagcm = confmatpercent\n",
    "        xticks = np.linspace(0, confmatpercent.shape[1]-1, confmatpercent.shape[1], dtype = int)\n",
    "        used_columns = []\n",
    "        for i in range(min(confmatpercent.shape)):\n",
    "            max_row_value = np.argmax(confmatpercent[i,:])\n",
    "            if max_row_value not in used_columns:\n",
    "                diagcm[:,[i,max_row_value]] = diagcm[:,[max_row_value,i]]\n",
    "                xticks[[i, max_row_value]] = xticks[[max_row_value, i]]\n",
    "                used_columns.append(i)\n",
    "            else:\n",
    "                if np.max(confmatpercent[i,:]) > diagcm[max_row_value,max_row_value]:\n",
    "                    diagcm[:,[i,max_row_value]] = diagcm[:,[max_row_value,i]]\n",
    "                    xticks[[i, max_row_value]] = xticks[[max_row_value, i]]\n",
    "                    used_columns.append(i)\n",
    "        dot_max = np.max(diagcm.flatten())\n",
    "        dot_min = 0\n",
    "        if dot_min != 0 or dot_max != 1:\n",
    "            frac = np.clip(diagcm, dot_min, dot_max)\n",
    "            old_range = dot_max - dot_min\n",
    "            frac = (frac - dot_min) / old_range\n",
    "        else:\n",
    "            frac = diagcm\n",
    "        xvalues = []\n",
    "        yvalues = []\n",
    "        sizes = []\n",
    "        for i in range(diagcm.shape[0]):\n",
    "            for j in range(diagcm.shape[1]):\n",
    "                xvalues.append(j)\n",
    "                yvalues.append(i)\n",
    "                sizes.append((frac[i,j]*35)**1.5)\n",
    "        size_legend_width = 0.5\n",
    "        height = diagcm.shape[0] * 0.3 + 1\n",
    "        height = max([1.5, height])\n",
    "        heatmap_width = diagcm.shape[1] * 0.35\n",
    "        width = (\n",
    "            heatmap_width\n",
    "            + size_legend_width\n",
    "            )\n",
    "        fig = plt.figure(figsize=(width, height))\n",
    "        axs = gridspec.GridSpec(\n",
    "            nrows=2,\n",
    "            ncols=2,\n",
    "            wspace=0.02,\n",
    "            hspace=0.04,\n",
    "            width_ratios=[\n",
    "                        heatmap_width,\n",
    "                        size_legend_width\n",
    "                        ],\n",
    "            height_ratios = [0.5, 10]\n",
    "            )\n",
    "        dot_ax = fig.add_subplot(axs[1, 0])\n",
    "        dot_ax.scatter(xvalues,yvalues, s = sizes, c = 'blue', norm=None, edgecolor='none')\n",
    "        y_ticks = range(diagcm.shape[0])\n",
    "        dot_ax.set_yticks(y_ticks)\n",
    "        dot_ax.set_yticklabels(y_ticks)\n",
    "        x_ticks = range(diagcm.shape[1])\n",
    "        dot_ax.set_xticks(x_ticks)\n",
    "        dot_ax.set_xticklabels(xticks, rotation=90)\n",
    "        dot_ax.tick_params(axis='both', labelsize='small')\n",
    "        dot_ax.grid(True, linewidth = 0.2)\n",
    "        dot_ax.set_axisbelow(True)\n",
    "        dot_ax.set_xlim(-0.5, diagcm.shape[1] + 0.5)\n",
    "        ymin, ymax = dot_ax.get_ylim()\n",
    "        dot_ax.set_ylim(ymax + 0.5, ymin - 0.5)\n",
    "        dot_ax.set_xlim(-1, diagcm.shape[1])\n",
    "        dot_ax.set_xlabel(xaxislabel)\n",
    "        dot_ax.set_ylabel(yaxislabel)\n",
    "        dot_ax.set_title(title)\n",
    "        size_legend_height = min(1.75, height)\n",
    "        wspace = 10.5 / width\n",
    "        axs3 = gridspec.GridSpecFromSubplotSpec(\n",
    "            2,\n",
    "            1,\n",
    "            subplot_spec=axs[1, 1],\n",
    "            wspace=wspace,\n",
    "            height_ratios=[\n",
    "                        size_legend_height / height,\n",
    "                        (height - size_legend_height) / height\n",
    "                        ]\n",
    "            )\n",
    "        diff = dot_max - dot_min\n",
    "        if 0.3 < diff <= 0.6:\n",
    "            step = 0.1\n",
    "        elif diff <= 0.3:\n",
    "            step = 0.05\n",
    "        else:\n",
    "            step = 0.2\n",
    "        fracs_legends = np.arange(dot_max, dot_min, step * -1)[::-1]\n",
    "        if dot_min != 0 or dot_max != 1:\n",
    "            fracs_values = (fracs_legends - dot_min) / old_range\n",
    "        else:\n",
    "            fracs_values = fracs_legends\n",
    "        size = (fracs_values * 35) ** 1.5\n",
    "        size_legend = fig.add_subplot(axs3[0])\n",
    "        size_legend.scatter(np.repeat(0, len(size)), range(len(size)), s=size, c = 'blue')\n",
    "        size_legend.set_yticks(range(len(size)))\n",
    "        labels = [\"{:.0%}\".format(x) for x in fracs_legends]\n",
    "        if dot_max < 1:\n",
    "            labels[-1] = \">\" + labels[-1]\n",
    "        size_legend.set_yticklabels(labels)\n",
    "        size_legend.set_yticklabels([\"{:.0%}\".format(x) for x in fracs_legends])\n",
    "        size_legend.tick_params(axis='y', left=False, labelleft=False, labelright=True)\n",
    "        size_legend.tick_params(axis='x', bottom=False, labelbottom=False)\n",
    "        size_legend.spines['right'].set_visible(False)\n",
    "        size_legend.spines['top'].set_visible(False)\n",
    "        size_legend.spines['left'].set_visible(False)\n",
    "        size_legend.spines['bottom'].set_visible(False)\n",
    "        size_legend.grid(False)\n",
    "        ymin, ymax = size_legend.get_ylim()\n",
    "        size_legend.set_ylim(ymin, ymax + 0.5)\n",
    "        fig.savefig(save_as, bbox_inches = 'tight')\n",
    "\n",
    "        return diagcm, xticks, axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateNCE(labels_true,labels_pred):\n",
    "    X = labels_true\n",
    "    Y = labels_pred\n",
    "    contTable = confusion_matrix(X,Y)\n",
    "    a = np.sum(contTable, axis = 1)\n",
    "    b = np.sum(contTable, axis = 0)\n",
    "    N = np.sum(contTable)\n",
    "    pij = contTable/N\n",
    "    pi = a/N\n",
    "    pj = b/N\n",
    "    Hyx = np.zeros(contTable.shape)\n",
    "    for i in range(contTable.shape[0]):\n",
    "        for j in range(contTable.shape[1]):\n",
    "            if pij[i,j] == 0:\n",
    "                Hyx[i,j] = 0\n",
    "            else:\n",
    "                Hyx[i,j] = pij[i,j]*np.log10(pij[i,j]/pi[i])\n",
    "    CE = -np.sum(Hyx)\n",
    "    Hyi = np.zeros(contTable.shape[1])\n",
    "    for j in range(contTable.shape[1]):\n",
    "        Hyi[j] = pj[j]*np.log10(pj[j])\n",
    "    Hy = -np.sum(Hyi)\n",
    "    NCE = CE/Hy\n",
    "    return NCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_adata = sc.read_h5ad()\n",
    "test_adata = sc.read_h5ad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = TimeMapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_label_train_70, valid_predlabels_train_70, test_labels, test_predlabels = tm.xgbclassifier(\n",
    "    train_anndata = train_adata,\n",
    "    test_anndata = test_adata\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validationconfmat, validationxticks, validationplot = tm.plotConfusionMatrix(\n",
    "    ytrue = validation_label_train_70,\n",
    "    ypred = valid_predlabels_train_70,\n",
    "    type = 'validation',\n",
    "    save_as = '',\n",
    "    title = '',\n",
    "    xaxislabel = 'Predicted',\n",
    "    yaxislabel = 'True'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappingconfmatP14vsP17, mappingxticksP14vsP17, mappingplotP14vsP17 = tm.plotConfusionMatrix(\n",
    "    ytrue = test_labels,\n",
    "    ypred = test_predlabels,\n",
    "    type = 'mapping',\n",
    "    save_as = '',\n",
    "    title = 'ARI = {:.3f}, NCE = {:.3f}'.format(adjusted_rand_score(labels_true = validation_label_train_70 labels_pred = valid_predlabels_train_70), calculateNCE(labels_true = validation_label_train_70, labels_pred = valid_predlabels_train_70)),\n",
    "    xaxislabel = '',\n",
    "    yaxislabel = ''\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
